{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Model Build"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["\n","import os\n","import numpy as np\n","from typing import Any\n","import tensorflow as tf\n","import tensorflow.keras as k\n","import matplotlib.pyplot as plt\n","import metrics\n","from pandas import DataFrame\n","from metrics import plot_confusion\n","from IPython.display import Image\n","from tensorflow.keras import models\n","from keras.utils import plot_model\n","from tqdm.notebook import tqdm\n","from tensorflow.keras.layers import Dense, Input, Layer, InputSpec, Dropout\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.initializers import VarianceScaling\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.cluster import KMeans\n","from data import load_data\n","from wordcloud import WordCloud\n","import seaborn as sns\n","import umap"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["from sklearn.metrics import pairwise\n","def pairwise_sqd_distance(X, batch_size):\n","    return pairwise.pairwise_distances(X, metric='sqeuclidean')\n","\n","    tiled = tf.tile(tf.expand_dims(X, axis=1), tf.stack([1, batch_size, 1]))\n","    tiled_trans = tf.transpose(tiled, perm=[1,0,2])\n","    diffs = tiled - tiled_trans\n","    sqd_dist_mat = tf.reduce_sum(tf.square(diffs), axis=2)\n","\n","    return sqd_dist_mat\n","\n","def make_q(z, batch_size, alpha):\n","\n","    sqd_dist_mat = np.float32(pairwise_sqd_distance(z, batch_size))\n","    q = tf.pow((1 + sqd_dist_mat/alpha), -(alpha+1)/2)\n","    q = tf.linalg.set_diag(q, tf.zeros(shape=[batch_size]))\n","    q = q / tf.reduce_sum(q, axis=0, keepdims=True)\n","    # q = 0.5*(q + tf.transpose(q))\n","    q = tf.clip_by_value(q, 1e-10, 1.0)\n","    \n","    return q"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["from linear_assignment import linear_assignment\n","\n","def cluster_acc(y_true, y_pred, y_pred_cluster):\n","    y_true = y_true.astype(np.int64)\n","    assert y_pred_cluster.size == y_true.size\n","    D = max(y_pred_cluster.max(), y_true.max()) + 1\n","    w = np.zeros((D, D), dtype=np.int64)\n","    for i in range(y_pred_cluster.size):\n","        w[y_pred[i], y_true[i]] += 1\n","    ind = linear_assignment(w.max() - w)\n","    c_loss = sum([w[i, j] for i, j in ind]) * 1.0 / y_pred_cluster.size\n","    print(f\"Cluster Loss {c_loss} on {y_pred_cluster.size} clusters\")\n","    return c_loss"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from sklearn.cluster import KMeans, DBSCAN, OPTICS, AgglomerativeClustering\n","from sklearn import mixture\n","from scipy.stats import multivariate_normal\n","\n","def do_clustering(clustering: str, n_clusters: int, z_state: DataFrame, params={}):\n","    \"\"\"\n","    Perform clustering on the data.\n","        -clustering: the clustering algorithm to use\n","        -n_clusters: the number of clusters to use\n","        -z_state: the data to cluster\n","        -params: dict, optional\n","            'eps' or 'min_samples' values for DBSCAN/OPTICS\n","    Returns:\n","        - the cluster assignments\n","        - cluster centers\n","    \"\"\"\n","    dbscan_eps = 1\n","    dbscan_min_samples = 5\n","    \n","    if 'eps' in params:\n","        dbscan_eps = params['eps']\n","    if 'min_samples' in params:\n","        dbscan_min_samples = params['min_samples']\n","\n","    if clustering == 'GMM':\n","        gmix = mixture.GaussianMixture(\n","            n_components=n_clusters, covariance_type='full')\n","        gmix.fit(z_state)\n","        y_pred = gmix.predict(z_state)\n","        # get centres\n","        centers = np.empty(shape=(gmix.n_components, z_state.shape[1]))\n","        for i in range(gmix.n_components):\n","            density = multivariate_normal(\n","                cov=gmix.covariances_[i],\n","                mean=gmix.means_[i]).logpdf(z_state)\n","            centers[i, :] = z_state[np.argmax(density)]\n","    elif clustering == 'Kmeans':\n","        kmeans = KMeans(n_clusters=n_clusters, n_init=10)\n","        y_pred = kmeans.fit_predict(z_state)\n","        centers = kmeans.cluster_centers_\n","    elif clustering == 'DBSCAN':\n","        dbscan = DBSCAN(\n","            eps=dbscan_eps,\n","            min_samples=dbscan_min_samples,\n","            metric='manhattan')\n","        y_pred = dbscan.fit_predict(z_state)\n","        centers = dbscan.components_\n","    elif clustering == 'OPTICS':\n","        optics = OPTICS(min_samples=dbscan_min_samples)\n","        y_pred = optics.fit_predict(z_state)\n","        centers = optics.components_\n","    elif clustering==\"agg\":\n","        agg = AgglomerativeClustering(n_clusters=n_clusters, affinity='manhattan', linkage='average')\n","        y_pred = agg.fit_predict(z_state)\n","        centers = None\n","    else:\n","        raise ValueError('Clustering algorithm not specified/unknown.')\n","\n","    return y_pred, centers"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# write_messages.py\n","\n","from jinja2 import Environment, FileSystemLoader\n","from pathlib import Path\n","\n","def write_results_page(clusters, save_dir, test_name):\n","    \n","    environment = Environment(loader=FileSystemLoader(\"templates/\"))\n","    template = environment.get_template(\"index.jinja\")\n","\n","    results_filename = os.path.join(save_dir, \"index.html\")\n","    results_template = environment.get_template(\"index.jinja\")\n","    context = {\n","        \"clusters\": clusters,\n","        \"test_name\": test_name,\n","    }\n","    with open(results_filename, mode=\"w\", encoding=\"utf-8\") as results:\n","        results.write(results_template.render(context))\n","        full_filename = Path(results_filename).absolute()\n","        print (f'... wrote results  <a href=\"{full_filename}\">{full_filename}</a>')"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def show_wordcloud(i: int, cluster: dict, filepath: str, width: int=16, save_only: bool=False)-> None:\n","    \"\"\"\n","    Show wordcloud for a cluster.\n","    \"\"\"\n","    freqs = cluster['freqs']\n","    frac = cluster['frac']\n","    n = cluster['n']\n","    name = cluster['name']\n","    print(f'{i}: \"{name}\", {n} items, ({frac*100:.2f}% confidence)')\n","    if len(freqs) > 0:\n","        wc = WordCloud(width=800, height=500).generate_from_frequencies(freqs)\n","        if not save_only:\n","            plt.figure(figsize=(width, width-1))\n","            plt.imshow(wc, interpolation='bilinear')\n","            plt.axis(\"off\")\n","            plt.show()\n","        wc.to_file(filepath)\n","    else:\n","        print(f\"No words for cluster {cluster}\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["from pickletools import optimize\n","from tabnanny import verbose\n","from unicodedata import name\n","import warnings \n","warnings.filterwarnings(\"ignore\")\n","\n","ENTITY_FILTER_LIST = ['GPE', 'PERSON', 'ORG', 'DATE', 'NORP',\n","    'TIME', 'PERCENT', 'LOC', 'QUANTITY', 'MONEY', 'FAC', 'CARDINAL',\n","    'EVENT', 'PRODUCT', 'WORK_OF_ART', 'ORDINAL', 'LANGUAGE']\n","\n","class DeepLatentCluster():\n","\n","    def __init__(\n","                self,\n","                run_name: str,\n","                config: dict=None,\n","                verbose: int=1,\n","                ):\n","\n","        \n","        self.x = None\n","        self.y = None\n","        self.mapping = None\n","        self.strings = None\n","        self.y_pred_last = None\n","        self.input_dim = 768\n","        self.batch_size = 256\n","        \n","        self.run_name = run_name\n","        self.model = None\n","        self.encoder = None\n","        self.autoencoder = None\n","        self.save_dir = None\n","        self.verbose = verbose\n","        \n","        # latent model config\n","        self.config = {\n","            \"layers_ae\": [\n","                {\"n\": 500, \"act\": None},\n","                {\"n\": 500, \"act\": None},\n","                {\"n\": 2000, \"act\": None},\n","            ],\n","            \"layer_ae_latent\": \n","                {\"n\": 40, \"act\": None},\n","            \"layers_latent_network\": [\n","                {\"n\": 2000, \"act\": None},\n","                {\"n\": 500, \"act\": None},\n","                {\"n\": 500, \"act\": None},\n","            ],\n","            \"output_fn\": 'sigmoid',\n","            \"opt\": k.optimizers.Adam(\n","                                lr=0.001,\n","                                beta_1=0.9,\n","                                beta_2=0.999,\n","                                epsilon=None,\n","                                decay=0.0,\n","                                amsgrad=False),\n","            \"loss\": k.losses.binary_crossentropy,\n","            \"train_size\": 10000,\n","            \"num_clusters\": 25,\n","            \"cluster\": \"GMM\",\n","            \"entities\": None,\n","            \"entity_count\": 10,\n","            \"loss_weights\": None,\n","            \"latent_weight\": 0.0001,\n","            \"reconstr_weight\": 1.0,\n","            \"max_iter\": 8000,\n","            \"pretrain_epochs\": 300,\n","            \"emb_size\": 768,\n","            \"alpha1\": 20,\n","            \"alpha2\":1,\n","            \"ae_init_fn\": VarianceScaling(\n","                                    mode='fan_in',\n","                                    scale=1. / 3.,\n","                                    distribution='uniform')\n","            }\n","        if config is not None:\n","            self.config = {**self.config, **config}\n","        if self.config['entities'] is not None and self.config['entity_count'] > 0:\n","            raise ValueError('entities and entity_count cannot both be specified')\n","        if self.config['entities'] is None:\n","            if self.config['entity_count'] == 0:\n","                self.config['entities'] = ENTITY_FILTER_LIST\n","            else:\n","                self.config['entities'] = ENTITY_FILTER_LIST[\n","                                            :self.config['entity_count']]\n","                \n","\n","    def output(self, s:str)->None:\n","        if self.verbose > 0:\n","            print(s)\n","\n","    def make_data(self, oversample: bool=True) -> None:\n","        \n","        self.output(\"Load Data\")\n","        self.x, self.y, self.mapping, self.strings = load_data(\n","                                    self.config['train_size'],\n","                                    entity_filter=self.config['entities'],\n","                                    get_text=True,\n","                                    oversample=oversample,\n","                                    verbose=self.verbose)\n","        self.input_dim = self.x.shape[1]\n","        self.output(\"Data Loaded\")   \n","\n","    \n","\n","    def test_loss(self, y, y_pred):\n","        return cluster_loss(self.cluster, self.num_clusters)(y, y_pred)\n","\n","    # create a Dense layer from a config\n","    @staticmethod\n","    def create_layer(config: dict, name: str, init_fn: str='glorot_uniform') -> Dense:\n","        \"\"\"\n","        Create a layer from a config dictionary.\n","        - config: dictionary of layer parameters\n","            - n: number of units\n","            - act: activation function\n","        \"\"\"\n","        print(f\"Layer {name}: {config['n']} \"\n","              f\"activation={config['act']}\")\n","        return Dense(\n","            name=name,\n","            units=config[\"n\"],\n","            activation=config[\"act\"],\n","            kernel_initializer=init_fn,\n","            kernel_regularizer='l1')\n","\n","    # build the autoencoder\n","\n","    def autoencoder_model(self, layer_specs: list, act: str='tanh', init_fn: str='glorot_uniform', verbose=0):\n","        \"\"\"\n","        Creates the autoencoder given\n","        -layer_specs: list of layer sizes.\n","            Model is symmetrical so only need to specify the first half.\n","        -act: activation function for hidden layers\n","        -init_fn: initializer for weights\n","\n","        returns:\n","            - the full autoencoder\n","            - the encoder only\n","        \"\"\"\n","        layers = len(layer_specs) - 1\n","        # input\n","        input_img = Input(shape=(layer_specs[0],), name='input')\n","        x = input_img\n","        encoder = [input_img]\n","        # hidden layers in encoder\n","        for i in range(layers-1):\n","            layer = Dense(\n","                layer_specs[i + 1],\n","                activation=act,\n","                kernel_initializer=init_fn,\n","                name=f'encoder_{i}')(encoder[-1])\n","            encoder += [layer]\n","            if verbose >= 2:\n","                print(f'encoder_{i}: {layer_specs[i+1]} '\n","                    f'activation={act}')\n","\n","        # latent layer\n","        latent = Dense(\n","            layer_specs[-1],\n","            kernel_initializer=init_fn,\n","            name=f'encoder_{layers - 1}')(encoder[-1])\n","        encoder += [latent]\n","        if verbose >= 2:\n","            print(f'encoder_{layers - 1}: {layer_specs[-1]}')\n","\n","        autoencoder = [encoder[-1]]\n","        # hidden layers in decoder\n","        for i in range(layers-1, 0, -1):\n","            layer = Dense(\n","                layer_specs[i],\n","                activation=act,\n","                kernel_initializer=init_fn,\n","                name=f'decoder_{i}')(autoencoder[-1])\n","            autoencoder += [layer]\n","            if verbose >= 2:\n","                print(f'encoder_{i}: {layer_specs[i]}'\n","                    f' activation={act}')\n","\n","        # output\n","        layer = Dense(\n","                layer_specs[0],\n","                kernel_initializer=init_fn,\n","                name='decoder_0')(autoencoder[-1])\n","        autoencoder += [layer]\n","        if verbose >= 2:\n","                print(f'output: {layer_specs[0]}'\n","                    f'')\n","        return (encoder, autoencoder)\n","\n","\n","    \n","    # create the latent_space model\n","\n","    def create_latent_space_model(self, input_layer: Dense) -> Model:\n","        \"\"\"\n","        Create the model for the latent space\n","        - input_layer: previous model output layer\n","        \"\"\"\n","        # build ml, the array of layers\n","        ml = [input_layer]\n","        layers = self.config['layers_latent_network']\n","        for n, l in enumerate(layers):\n","            ml.append(self.create_layer(l, f\"latent_{n}\")(ml[-1]))\n","\n","        out_config = {**layers[0], \"act\": self.config['output_fn']}\n","        ml.append(self.create_layer(out_config, \"latent_out\")(ml[-1]))\n","        return ml\n","\n","    def create_model(self) -> Model:\n","        \"\"\"\n","        Create the entire model.\n","        \n","        \"\"\"\n","        print(\"Autoencoder\")\n","        # enc = self.create_ae_encoder_model()\n","        # dec = self.create_ae_decoder_model(\n","        #     input_layer=enc[-1])\n","\n","        enc, dec = self.autoencoder_model(\n","            [768, 500, 500, 2000, 40], \n","            init_fn=self.config['ae_init_fn'], \n","            act='relu',\n","            verbose=self.verbose)\n","        print(\"Latent Model\")\n","\n","        latent_space = self.create_latent_space_model(\n","            input_layer=enc[-1])\n","        self.model = k.Model(\n","            name=\"full-model\",\n","            inputs=enc[0],\n","            outputs=[\n","                dec[-1],\n","                latent_space[-1],\n","                ])\n","        \n","        self.autoencoder = k.Model(\n","            name=\"ae-model\",\n","            inputs=enc[0],\n","            outputs=[\n","                dec[-1],\n","                ])\n","\n","        self.encoder = k.Model(\n","            name=\"encoder\",\n","            inputs=enc[0],\n","            outputs=[\n","                enc[-1],\n","                ])\n","\n","\n","    def make_model(self) -> None:\n","        self.create_model()\n","        \n","        self.model.compile(\n","            loss=[\n","                self.latent_loss(\n","                        self.model.get_layer(\"encoder_2\").get_weights()[0])],\n","            # loss_weights=self.config['loss_weights'],\n","            optimizer=SGD(learning_rate=0.5, momentum=0.9))\n","        self.output(\"model compiled\")\n","\n","        self.autoencoder.compile(optimizer='adam', loss='mse')\n","        \n","        self.save_dir = f'./results/{self.run_name}'\n","        if not os.path.exists(self.save_dir):\n","            # create save dir\n","            os.makedirs(self.save_dir)\n","        img_file = os.path.join(self.save_dir, f'{self.run_name}_model.png')\n","        plot_model(self.model, to_file=img_file, show_shapes=True)\n","        Image(filename=img_file)\n","\n","    def reconstr_loss(self, x, x_pred):\n","        return tf.reduce_mean(tf.square(tf.subtract(x, x_pred)))\n","\n","    def latent_loss(self, z_enc):\n","        def loss (y, y_pred):\n","            p = make_q(y_pred, self.batch_size, alpha=self.config['alpha1'])\n","            q = make_q(z_enc, self.batch_size, alpha=self.config['alpha2'])\n","            latent_loss = tf.reduce_sum(-(tf.multiply(p, tf.math.log(q))))\n","            return latent_loss\n","        return loss\n","\n","    def train_model(self, verbose:int=1) -> None:\n","        \"\"\"\n","        Run the model.\n","        \"\"\"\n","        if verbose:\n","            self.verbose = verbose\n","            \n","        if self.x is None:\n","            self.make_data(oversample=True)\n","            self.output(\"Data Loaded\")   \n","        \n","        if self.model is None:\n","            self.make_model()\n","        \n","\n","        self.output(\"Training autoencoder\")\n","        early_stopping_cb = EarlyStopping(\n","            monitor='loss', patience=10, verbose=1, min_delta=0.00001)\n","        history = self.autoencoder.fit(\n","                                self.x,\n","                                self.x,\n","                                batch_size=self.batch_size,\n","                                epochs=self.config[\"pretrain_epochs\"], \n","                                verbose=self.verbose,\n","                                callbacks=[early_stopping_cb],\n","                                )\n","        self.autoencoder.save_weights(os.path.join(self.save_dir, 'ae_weights.h5'))\n","        self.output(\"Trained autoencoder\")\n","        if self.verbose > 0:\n","            # summarize history for loss\n","            plt.plot(history.history['loss'])\n","            plt.title('Autoencoder pretraining loss')\n","            plt.ylabel('loss')\n","            plt.xlabel('epoch')\n","            plt.show()\n","\n","        # # init cluster centres before train\n","        # self.init_cluster_centers()\n","\n","        # train full model\n","        losses = self.train()\n","        if self.verbose > 0:\n","            # summarize history for loss\n","            plt.plot(losses)\n","            plt.title('Full model loss')\n","            plt.ylabel('loss')\n","            plt.xlabel('epoch')\n","            plt.show()\n","\n","        print(\"Training Done\")\n","\n","    def aux_target_distribution(self, q):\n","        #sum column wise\n","        row_sum = q.sum(axis=0)\n","        # q_ij ^2 / row sum\n","        top = q ** 2 / row_sum\n","        # then / column sum\n","        return (top.T / top.sum(axis=1)).T\n","\n","    def train_step(self, x, y):\n","        with tf.GradientTape() as tape:\n","            dec, lat = self.model(x, training=True)\n","            loss_l =  self.latent_loss(self.encoder(x))(y, lat)\n","            loss_r = self.reconstr_loss(x, dec)\n","            loss_value = self.config['latent_weight'] * loss_l +\\\n","                         self.config['reconstr_weight'] * loss_r\n","\n","            # Add any extra losses created during the forward pass.\n","            # loss_value += sum(self.losses)\n","        grads = tape.gradient(loss_value, self.model.trainable_weights)\n","        optimizer = self.config['opt']\n","        optimizer.apply_gradients(zip(grads, self.model.trainable_weights))\n","        self.train_acc_metric.update_state(y, lat)\n","        return loss_value\n","        \n","    def train(self):\n","        self.train_acc_metric = k.metrics.SparseCategoricalAccuracy()\n","\n","        update_interval = 140\n","        index_array = np.arange(self.x.shape[0])\n","        tol = 0.0001  # tolerance threshold to stop training\n","        loss = 0\n","        index = 0\n","        update_interval = 140\n","        losses = []\n","        for ite in range(int(self.config['max_iter'])):\n","            if ite % update_interval == 0:\n","                print(f\"Iter:{ite} -> loss:{loss}\")\n","            idx = index_array[\n","                    index * self.batch_size : \n","                    min((index+1) * self.batch_size , self.x.shape[0])]\n","            loss = self.train_step(self.x[idx], self.y[idx])\n","            losses += [loss]\n","        if self.verbose == 0:\n","            # final values\n","            print(f'Iter: {ite} loss={loss}')\n","        self.model.save_weights(os.path.join(self.save_dir, 'lat_model_final.h5'))\n","        return losses\n","\n","    def cluster_pred_acc(self):\n","        NER_only= DataFrame({'y':self.y, 'y_clus':self.y_pred})\n","        unk_tuple = [k for k, v in self.mapping.items() if v == 'UNKNOWN']\n","        unk_idx = unk_tuple[0] if len(unk_tuple) > 0 else None\n","        NER_only.drop(NER_only.index[NER_only['y']==unk_idx], inplace=True)\n","        NER_match = NER_only[NER_only['y']==NER_only['y_clus']]\n","        # fraction that match\n","        frac = NER_match.shape[0]/NER_only.shape[0]\n","        return frac\n","\n","    def make_load_model(self):\n","        self.make_model()\n","\n","        ae_weights_file = os.path.join(self.save_dir, 'ae_weights.h5')\n","        self.output(f\"Loading AE weights from {ae_weights_file}\")\n","        self.autoencoder.load_weights(ae_weights_file)\n","        \n","        model_weights_file = os.path.join(self.save_dir, 'lat_model_final.h5')\n","        self.output(f\"Loading model weights from {model_weights_file}\")\n","        self.model.load_weights(model_weights_file)\n","\n","    \n","    def evaluate_model(self, eval_size: int, verbose:int=1) -> None:\n","        \"\"\"\n","        Run the model.\n","        \"\"\"\n","        self.verbose = verbose\n","\n","        if self.config['train_size'] != eval_size or self.x is None:\n","            self.output(\"Load Data\")\n","            self.x, self.y, self.mapping, self.strings = load_data(\n","                                                            eval_size,\n","                                                            get_text=True,\n","                                                            verbose=verbose)\n","            self.output(\"Data Loaded\")   \n","\n","        self.make_load_model()\n","        \n","        \n","        # predict cluster labels\n","        self.output(\"Predicting...\")\n","        \n","        # run the model on sampled x in batches\n","        num_batches = len(self.x) // self.batch_size\n","        z_list = []\n","        for i in tqdm(range(num_batches)):\n","            idx = np.arange(i * self.batch_size, (i + 1) * self.batch_size)\n","            x = self.x[idx]\n","            _, z = self.model.predict(x)\n","            z_list += [z]\n","\n","        z_space =  np.vstack(np.array(z_list))\n","        if z_space.shape[0] > 10000:\n","            indices = np.random.choice(z_space.shape[0], 1000, replace=False)\n","            z_sample = z_space[indices]\n","            labels = self.y[indices]\n","        else:\n","            z_sample = z_space.shape\n","            labels = self.y\n","        \n","        print(f\"Clustering {z_sample.shape[0]} points\")\n","        self.y_pred, _ = do_clustering(\n","                                clustering=\"GMM\",\n","                                n_clusters=self.config['num_clusters'],\n","                                z_state=z_sample)\n","\n","        labels = np.asarray(\n","            [(self.mapping[l] if l in self.mapping else l) for l in labels ])\n","        mapper = umap.UMAP(metric='manhattan').fit(z_sample)\n","        import umap.plot as plt_u\n","        plt_u.points(mapper, labels=labels)\n","\n","\n","        # confusion matrix\n","        cm_width = max(8, len(np.unique(self.y_pred)) * 2)\n","        cm_width = min(16, cm_width)\n","        plot_confusion(self.y, self.y_pred, self.mapping, self.save_dir, cm_width)\n","\n","        # show wordclouds for each cluster\n","        self.output (\"CLUSTERS\")\n","        clusters = {}\n","        predicted = DataFrame({\n","            'text':self.strings,\n","            'y_pred':self.y_pred,\n","            'y_true':self.y})\n","        for cluster_no in tqdm(range(self.num_clusters)):\n","            y_pred_for_key = predicted[predicted['y_pred']==cluster_no]\n","            true_label = 'UNKNOWN'\n","            modal_value = y_pred_for_key['y_true'].mode()\n","            if len(modal_value)>0:\n","                if modal_value[0] in self.mapping:\n","                    true_label = self.mapping[modal_value[0]]\n","                # confidence - fraction of this cluster that is actually this cluster\n","                y_true_this_cluster = len(\n","                    y_pred_for_key[y_pred_for_key['y_true']==modal_value[0]])\n","                frac = y_true_this_cluster/len(y_pred_for_key)\n","            else:\n","                frac = 0\n","\n","            # wordcloud\n","            unique, counts = np.unique(y_pred_for_key['text'], return_counts=True)\n","            freq_list = np.asarray((unique, counts)).T\n","            freq_list =  sorted(freq_list, key=lambda x: -x[1])[0:50]\n","            freqs = {w: f for w,f in freq_list}\n","            entry = {'freqs':freqs, 'frac':frac, 'n':len(y_pred_for_key)}\n","            if true_label == 'UNKNOWN':\n","                clusters[f\"UNK-{cluster_no}\"] = entry\n","            elif true_label in clusters:\n","                if clusters[true_label]['frac'] < frac:\n","                    # we found a better cluster for this label\n","                    clusters[true_label] = entry\n","                else:\n","                    # this cluster is worse than this one, so it's unknown\n","                    clusters[f\"UNK-{cluster_no} Was {true_label}\"] = entry\n","            else:\n","                clusters[true_label] = entry\n","\n","        cluster_list = [{\n","            **clusters[c],\n","            'name': c,\n","            'idx': idx} for idx, c in enumerate(clusters)]\n","        cluster_list = sorted(cluster_list, key=lambda x: -x['frac'])\n","\n","        display_list = []\n","        # show unknown clusters first\n","        for i, cluster in enumerate(cluster_list):\n","            if cluster['name'][0:3] == \"UNK\":\n","                save_file = os.path.join(self.save_dir,\n","                                        f\"wordcloud-{cluster['name']}.png\")\n","                show_wordcloud(i, cluster, save_file, save_only=True)\n","                display_list.append(cluster)\n","\n","        # next show known clusters\n","        for i, cluster in enumerate(cluster_list):\n","            if cluster['name'][0:3] != \"UNK\":\n","                save_file = os.path.join(self.save_dir,\n","                                        f\"wordcloud-{cluster['name']}.png\")\n","                show_wordcloud(i, cluster, save_file, save_only=True)\n","                display_list.append(cluster)\n","\n","        \n","        self.output(write_results_page(display_list, self.save_dir, self.run_name))\n","\n","\n","    def visualise_tsne(self):\n","        tsne = TSNE(\n","                n_components=2,\n","                verbose=1,\n","                random_state=123,\n","                n_iter=300,\n","                learning_rate='auto')\n","        x_enc = self.encoder.predict(self.x)\n","        z = tsne.fit_transform(x_enc)\n","        df_tsne = pd.DataFrame()\n","        df_tsne[\"y\"] = self.y_pred\n","        df_tsne[\"comp-1\"] = z[:,0]\n","        df_tsne[\"comp-2\"] = z[:,1]\n","        plt.figure(figsize=(18,14))\n","        sns.scatterplot(x=\"comp-1\", y=\"comp-2\", hue=df_tsne.y.tolist(),\n","                palette=sns.color_palette(\n","                        \"hls\",\n","                        len(ENTITY_FILTER_LIST)),\n","                data=df_tsne).set(title=\"Labelled embeddings T-SNE projection\") \n","\n","    \n","    def visualise_umap(self, sample:int=1000, embs:str=\"z\"):\n","        if embs == \"z\":\n","            # encoder output\n","            z_enc = self.encoder.predict(self.x)\n","        elif embs == \"x\":\n","            # raw BERT embeddings\n","            z_enc = self.x\n","        indices = np.random.choice(z_enc.shape[0], sample, replace=False)\n","        labels = self.y_pred[indices]\n","        labels = np.asarray(\n","            [(self.mapping[l] if l in self.mapping else l) for l in labels ])\n","        z_sample = z_enc[indices]\n","        mapper = umap.UMAP(metric='manhattan').fit(z_sample)\n","        import umap.plot as plt_u\n","        plt_u.points(mapper, labels=labels)\n","        umap.plot.plt.show()\n","    \n","    \n","    \n","\n","    def train_and_evaluate_model(self, eval_size, verbose=1):\n","        \"\"\"\n","        Make and evaluate a model.\n","        Arguments:\n","            run_name: name of the run.\n","            data_rows: number of rows to use.\n","            n_clusters: number of clusters to use.\n","            entity_count: number of entities to use.\n","        \"\"\"\n","        self.verbose = verbose\n","        self.make_model()\n","        self.train_model()\n","        self.evaluate_model(eval_size)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'dc' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Will\\Projects\\MSc\\project\\src\\joint_model_trg.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#Y114sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdel\u001b[39;00m dc\n","\u001b[1;31mNameError\u001b[0m: name 'dc' is not defined"]}],"source":["del dc"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Autoencoder\n","Latent Model\n","Layer latent_0: 2000 activation=None\n","Layer latent_1: 500 activation=None\n","Layer latent_2: 500 activation=None\n","Layer latent_out: 2000 activation=sigmoid\n","model compiled\n","Model: \"ae-model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input (InputLayer)          [(None, 768)]             0         \n","                                                                 \n"," encoder_0 (Dense)           (None, 500)               384500    \n","                                                                 \n"," encoder_1 (Dense)           (None, 500)               250500    \n","                                                                 \n"," encoder_2 (Dense)           (None, 2000)              1002000   \n","                                                                 \n"," encoder_3 (Dense)           (None, 40)                80040     \n","                                                                 \n"," decoder_3 (Dense)           (None, 2000)              82000     \n","                                                                 \n"," decoder_2 (Dense)           (None, 500)               1000500   \n","                                                                 \n"," decoder_1 (Dense)           (None, 500)               250500    \n","                                                                 \n"," decoder_0 (Dense)           (None, 768)               384768    \n","                                                                 \n","=================================================================\n","Total params: 3,434,808\n","Trainable params: 3,434,808\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n"]}],"source":["tf.get_logger().setLevel('ERROR')\n","\n","dc = DeepLatentCluster('test-latent', \n","                      {\n","                        'train_size':1000,\n","                        'reconstr_weight':1.0, 'latent_weight':1e-5})\n","dc.make_model()\n","print(dc.autoencoder.summary())\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Load Data\n","Loading ./data/conll_spacy_1000.pkl\n","LOADED {1: 'UNKNOWN', 4: 'ORG', 2: 'PERSON', 9: 'DATE', 5: 'GPE', 6: 'LOC', 13: 'QUANTITY', 11: 'PERCENT', 8: 'EVENT', 12: 'MONEY', 3: 'NORP', 14: 'ORDINAL', 16: 'FAC', 10: 'TIME', 15: 'CARDINAL', 7: 'PRODUCT'}\n","Done: (658, 772)\n","Train data balance:\n","[[  2 153]\n"," [  3   7]\n"," [  4 122]\n"," [  5 249]\n"," [  6   7]\n"," [  9 103]\n"," [ 10   2]\n"," [ 11   3]\n"," [ 12   7]\n"," [ 13   5]]\n","Balancing data\n","x: (2490, 768), y: (2490,)\n","{0: 'PERSON', 1: 'NORP', 2: 'ORG', 3: 'GPE', 4: 'LOC', 5: 'DATE', 6: 'TIME', 7: 'PERCENT', 8: 'MONEY', 9: 'QUANTITY'}\n","Data Loaded\n","Training autoencoder\n","Epoch 1/300\n","10/10 [==============================] - 1s 19ms/step - loss: 0.1376\n","Epoch 2/300\n","10/10 [==============================] - 0s 8ms/step - loss: 0.1264\n","Epoch 3/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0970\n","Epoch 4/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0891\n","Epoch 5/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0847\n","Epoch 6/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0840\n","Epoch 7/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0837\n","Epoch 8/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0836\n","Epoch 9/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0835\n","Epoch 10/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0835\n","Epoch 11/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0835\n","Epoch 12/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0834\n","Epoch 13/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0834\n","Epoch 14/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0829\n","Epoch 15/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0780\n","Epoch 16/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0730\n","Epoch 17/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0680\n","Epoch 18/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0627\n","Epoch 19/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0580\n","Epoch 20/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0540\n","Epoch 21/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0502\n","Epoch 22/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0462\n","Epoch 23/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0424\n","Epoch 24/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0399\n","Epoch 25/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0379\n","Epoch 26/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0361\n","Epoch 27/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0345\n","Epoch 28/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0331\n","Epoch 29/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0320\n","Epoch 30/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0311\n","Epoch 31/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0302\n","Epoch 32/300\n","10/10 [==============================] - 0s 3ms/step - loss: 0.0295\n","Epoch 33/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0287\n","Epoch 34/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0280\n","Epoch 35/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0273\n","Epoch 36/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0265\n","Epoch 37/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0259\n","Epoch 38/300\n","10/10 [==============================] - 0s 3ms/step - loss: 0.0254\n","Epoch 39/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0249\n","Epoch 40/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0245\n","Epoch 41/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0242\n","Epoch 42/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0238\n","Epoch 43/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0234\n","Epoch 44/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0230\n","Epoch 45/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0226\n","Epoch 46/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0222\n","Epoch 47/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0219\n","Epoch 48/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0216\n","Epoch 49/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0215\n","Epoch 50/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0212\n","Epoch 51/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0209\n","Epoch 52/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0205\n","Epoch 53/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0202\n","Epoch 54/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0199\n","Epoch 55/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0196\n","Epoch 56/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0193\n","Epoch 57/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0190\n","Epoch 58/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0187\n","Epoch 59/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0187\n","Epoch 60/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0183\n","Epoch 61/300\n","10/10 [==============================] - 0s 3ms/step - loss: 0.0181\n","Epoch 62/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0179\n","Epoch 63/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0176\n","Epoch 64/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0173\n","Epoch 65/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0171\n","Epoch 66/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0169\n","Epoch 67/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0167\n","Epoch 68/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0166\n","Epoch 69/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0166\n","Epoch 70/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0162\n","Epoch 71/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0159\n","Epoch 72/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0158\n","Epoch 73/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0155\n","Epoch 74/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0154\n","Epoch 75/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0152\n","Epoch 76/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0151\n","Epoch 77/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0149\n","Epoch 78/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0147\n","Epoch 79/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0145\n","Epoch 80/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0143\n","Epoch 81/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0141\n","Epoch 82/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0139\n","Epoch 83/300\n","10/10 [==============================] - 0s 3ms/step - loss: 0.0137\n","Epoch 84/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0135\n","Epoch 85/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0134\n","Epoch 86/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0133\n","Epoch 87/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0132\n","Epoch 88/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0131\n","Epoch 89/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0129\n","Epoch 90/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0127\n","Epoch 91/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0126\n","Epoch 92/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0125\n","Epoch 93/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0123\n","Epoch 94/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0121\n","Epoch 95/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0119\n","Epoch 96/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0118\n","Epoch 97/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0117\n","Epoch 98/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0116\n","Epoch 99/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0115\n","Epoch 100/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0113\n","Epoch 101/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0113\n","Epoch 102/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0112\n","Epoch 103/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0111\n","Epoch 104/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0110\n","Epoch 105/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0109\n","Epoch 106/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0107\n","Epoch 107/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0105\n","Epoch 108/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0104\n","Epoch 109/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0102\n","Epoch 110/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0101\n","Epoch 111/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0099\n","Epoch 112/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0098\n","Epoch 113/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0097\n","Epoch 114/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0096\n","Epoch 115/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0095\n","Epoch 116/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0094\n","Epoch 117/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0093\n","Epoch 118/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0094\n","Epoch 119/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0096\n","Epoch 120/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0094\n","Epoch 121/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0094\n","Epoch 122/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0094\n","Epoch 123/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0093\n","Epoch 124/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0090\n","Epoch 125/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0088\n","Epoch 126/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0086\n","Epoch 127/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0085\n","Epoch 128/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0084\n","Epoch 129/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0083\n","Epoch 130/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0082\n","Epoch 131/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0081\n","Epoch 132/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0080\n","Epoch 133/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0079\n","Epoch 134/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0079\n","Epoch 135/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0079\n","Epoch 136/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0079\n","Epoch 137/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0078\n","Epoch 138/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0076\n","Epoch 139/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0075\n","Epoch 140/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0074\n","Epoch 141/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0074\n","Epoch 142/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0074\n","Epoch 143/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0075\n","Epoch 144/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0075\n","Epoch 145/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0076\n","Epoch 146/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0074\n","Epoch 147/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0073\n","Epoch 148/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0071\n","Epoch 149/300\n","10/10 [==============================] - 0s 2ms/step - loss: 0.0072\n","Epoch 150/300\n"," 1/10 [==>...........................] - ETA: 0s - loss: 0.0068"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Will\\Projects\\MSc\\project\\src\\joint_model_trg.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dc\u001b[39m.\u001b[39mmake_data()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m dc\u001b[39m.\u001b[39;49mtrain_model(verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n","\u001b[1;32mc:\\Users\\Will\\Projects\\MSc\\project\\src\\joint_model_trg.ipynb Cell 10\u001b[0m in \u001b[0;36mDeepLatentCluster.train_model\u001b[1;34m(self, verbose)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X12sZmlsZQ%3D%3D?line=299'>300</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(\u001b[39m\"\u001b[39m\u001b[39mTraining autoencoder\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X12sZmlsZQ%3D%3D?line=300'>301</a>\u001b[0m early_stopping_cb \u001b[39m=\u001b[39m EarlyStopping(\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X12sZmlsZQ%3D%3D?line=301'>302</a>\u001b[0m     monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, min_delta\u001b[39m=\u001b[39m\u001b[39m0.00001\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X12sZmlsZQ%3D%3D?line=302'>303</a>\u001b[0m history \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mautoencoder\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X12sZmlsZQ%3D%3D?line=303'>304</a>\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X12sZmlsZQ%3D%3D?line=304'>305</a>\u001b[0m                         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X12sZmlsZQ%3D%3D?line=305'>306</a>\u001b[0m                         batch_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X12sZmlsZQ%3D%3D?line=306'>307</a>\u001b[0m                         epochs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconfig[\u001b[39m\"\u001b[39;49m\u001b[39mpretrain_epochs\u001b[39;49m\u001b[39m\"\u001b[39;49m], \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X12sZmlsZQ%3D%3D?line=307'>308</a>\u001b[0m                         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X12sZmlsZQ%3D%3D?line=308'>309</a>\u001b[0m                         callbacks\u001b[39m=\u001b[39;49m[early_stopping_cb],\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X12sZmlsZQ%3D%3D?line=309'>310</a>\u001b[0m                         )\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X12sZmlsZQ%3D%3D?line=310'>311</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautoencoder\u001b[39m.\u001b[39msave_weights(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_dir, \u001b[39m'\u001b[39m\u001b[39mae_weights.h5\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X12sZmlsZQ%3D%3D?line=311'>312</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput(\u001b[39m\"\u001b[39m\u001b[39mTrained autoencoder\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[1;32mc:\\Users\\Will\\Anaconda3\\envs\\tf-27\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[1;32mc:\\Users\\Will\\Anaconda3\\envs\\tf-27\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n","File \u001b[1;32mc:\\Users\\Will\\Anaconda3\\envs\\tf-27\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n","File \u001b[1;32mc:\\Users\\Will\\Anaconda3\\envs\\tf-27\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n","File \u001b[1;32mc:\\Users\\Will\\Anaconda3\\envs\\tf-27\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n","File \u001b[1;32mc:\\Users\\Will\\Anaconda3\\envs\\tf-27\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n","File \u001b[1;32mc:\\Users\\Will\\Anaconda3\\envs\\tf-27\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n","File \u001b[1;32mc:\\Users\\Will\\Anaconda3\\envs\\tf-27\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n","File \u001b[1;32mc:\\Users\\Will\\Anaconda3\\envs\\tf-27\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["dc.make_data()\n","dc.train_model(verbose=0)\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Load Data\n","Loading ./data/conll_spacy_1000.pkl\n","LOADED {1: 'UNKNOWN', 4: 'ORG', 2: 'PERSON', 9: 'DATE', 5: 'GPE', 6: 'LOC', 13: 'QUANTITY', 11: 'PERCENT', 8: 'EVENT', 12: 'MONEY', 3: 'NORP', 14: 'ORDINAL', 16: 'FAC', 10: 'TIME', 15: 'CARDINAL', 7: 'PRODUCT'}\n","Done: (3348, 772)\n","Train data balance:\n","[[   1 2672]\n"," [   2  153]\n"," [   3    7]\n"," [   4  122]\n"," [   5  249]\n"," [   6    7]\n"," [   7    1]\n"," [   8    5]\n"," [   9  103]\n"," [  10    2]\n"," [  11    3]\n"," [  12    7]\n"," [  13    5]\n"," [  14    3]\n"," [  15    1]\n"," [  16    8]]\n","Balancing data\n","x: (42752, 768), y: (42752,)\n","{0: 'UNKNOWN', 1: 'PERSON', 2: 'NORP', 3: 'ORG', 4: 'GPE', 5: 'LOC', 6: 'PRODUCT', 7: 'EVENT', 8: 'DATE', 9: 'TIME', 10: 'PERCENT', 11: 'MONEY', 12: 'QUANTITY', 13: 'ORDINAL', 14: 'CARDINAL', 15: 'FAC'}\n","Data Loaded\n","Autoencoder\n","Latent Model\n","Layer latent_0: 2000 activation=None\n","Layer latent_1: 500 activation=None\n","Layer latent_2: 500 activation=None\n","Layer latent_out: 2000 activation=sigmoid\n","model compiled\n","Loading AE weights from ./results/test-latent\\ae_weights.h5\n","Loading model weights from ./results/test-latent\\lat_model_final.h5\n","Predicting...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b53792dac9941b59510a8482687f16b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/167 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["8/8 [==============================] - 1s 3ms/step\n","8/8 [==============================] - 0s 4ms/step\n","8/8 [==============================] - 0s 4ms/step\n","8/8 [==============================] - 0s 3ms/step\n","8/8 [==============================] - 0s 4ms/step\n","8/8 [==============================] - 0s 3ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 3ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 3ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 3ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 1ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","8/8 [==============================] - 0s 2ms/step\n","Clustering 1000 points\n"]},{"ename":"ValueError","evalue":"Found input variables with inconsistent numbers of samples: [42752, 1000]","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Will\\Projects\\MSc\\project\\src\\joint_model_trg.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dc\u001b[39m.\u001b[39;49mevaluate_model(\u001b[39m1000\u001b[39;49m)\n","\u001b[1;32mc:\\Users\\Will\\Projects\\MSc\\project\\src\\joint_model_trg.ipynb Cell 12\u001b[0m in \u001b[0;36mDeepLatentCluster.evaluate_model\u001b[1;34m(self, eval_size, verbose)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X13sZmlsZQ%3D%3D?line=457'>458</a>\u001b[0m cm_width \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39m8\u001b[39m, \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_pred)) \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X13sZmlsZQ%3D%3D?line=458'>459</a>\u001b[0m cm_width \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(\u001b[39m16\u001b[39m, cm_width)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X13sZmlsZQ%3D%3D?line=459'>460</a>\u001b[0m plot_confusion(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_pred, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmapping, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_dir, cm_width)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X13sZmlsZQ%3D%3D?line=461'>462</a>\u001b[0m \u001b[39m# show wordclouds for each cluster\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X13sZmlsZQ%3D%3D?line=462'>463</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput (\u001b[39m\"\u001b[39m\u001b[39mCLUSTERS\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[1;32mc:\\Users\\Will\\Projects\\MSc\\project\\src\\metrics.py:37\u001b[0m, in \u001b[0;36mplot_confusion\u001b[1;34m(y, y_pred, mapping, save_dir, size, details)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot_confusion\u001b[39m(y, y_pred, mapping, save_dir: \u001b[39mstr\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, size: \u001b[39mint\u001b[39m\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, details: \u001b[39mbool\u001b[39m\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m     36\u001b[0m     sns\u001b[39m.\u001b[39mset(font_scale\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m     confusion_matrix \u001b[39m=\u001b[39m sklearn\u001b[39m.\u001b[39;49mmetrics\u001b[39m.\u001b[39;49mconfusion_matrix(y, y_pred)\n\u001b[0;32m     38\u001b[0m     entity_label_tups \u001b[39m=\u001b[39m [(k,v) \u001b[39mfor\u001b[39;00m k,v \u001b[39min\u001b[39;00m mapping\u001b[39m.\u001b[39mitems()]\n\u001b[0;32m     39\u001b[0m     entity_labels \u001b[39m=\u001b[39m [v \u001b[39mfor\u001b[39;00m v,v \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(entity_label_tups, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m tup: tup[\u001b[39m0\u001b[39m])]\n","File \u001b[1;32mc:\\Users\\Will\\Anaconda3\\envs\\tf-27\\lib\\site-packages\\sklearn\\metrics\\_classification.py:307\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconfusion_matrix\u001b[39m(\n\u001b[0;32m    223\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, labels\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, normalize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[0;32m    224\u001b[0m ):\n\u001b[0;32m    225\u001b[0m     \u001b[39m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \n\u001b[0;32m    227\u001b[0m \u001b[39m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 307\u001b[0m     y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[0;32m    308\u001b[0m     \u001b[39mif\u001b[39;00m y_type \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    309\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not supported\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m y_type)\n","File \u001b[1;32mc:\\Users\\Will\\Anaconda3\\envs\\tf-27\\lib\\site-packages\\sklearn\\metrics\\_classification.py:84\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[0;32m     58\u001b[0m     \u001b[39m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[39m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m     85\u001b[0m     type_true \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     86\u001b[0m     type_pred \u001b[39m=\u001b[39m type_of_target(y_pred, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my_pred\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[1;32mc:\\Users\\Will\\Anaconda3\\envs\\tf-27\\lib\\site-packages\\sklearn\\utils\\validation.py:387\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    385\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    386\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 387\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    390\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [42752, 1000]"]},{"data":{"image/png":"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","text/plain":["<Figure size 800x800 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["dc.evaluate_model(1000)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'stop' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\Will\\Projects\\MSc\\project\\src\\joint_model_trg.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Will/Projects/MSc/project/src/joint_model_trg.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m stop\n","\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"]}],"source":["stop"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# %history -g -f jupyter_history.py\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["del dc"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dc = DeepCluster('test-0-40latent-q', dims=[768, 500, 500, 2000, 40],\n","    entity_count=10, train_size=0, num_clusters=25, maxiter=10000)\n","dc.train_and_evaluate_model(10000, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dc = DeepCluster('test-0-40latent', dims=[768, 500, 500, 2000, 40],\n","    entity_count=10, train_size=0, num_clusters=25, maxiter=2000)\n","dc.train_and_evaluate_model(10000, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dc = DeepCluster('test-0-40latent', dims=[768, 500, 500, 2000, 40],\n","    entity_count=10, train_size=0, num_clusters=25, maxiter=2000)\n","dc.train_and_evaluate_model(10000, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dc = DeepCluster('test-0-40latent', dims=[768, 500, 500, 2000, 40],\n","    entity_count=10, train_size=0, num_clusters=25, maxiter=2000)\n","dc.evaluate_model(10000, verbose=0)\n","print(\"UMAP\")\n","dc.visualise_umap(5000, embs=\"x\")\n","dc.visualise_umap(5000, embs=\"z\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","dc = DeepCluster('test-0-100latent', dims=[768, 500, 500, 2000, 100],\n","    entity_count=10, train_size=0, num_clusters=25, maxiter=1000)\n","dc.train_and_evaluate_model(10000, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dc = DeepCluster('test-0-250latent', dims=[768, 500, 500, 2000, 250],\n","    entity_count=10, train_size=0, num_clusters=25, maxiter=1000)\n","dc.train_and_evaluate_model(10000, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","dc.visualise_tsne()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dc = DeepCluster('test1', train_size=0, num_clusters=25).train_and_evaluate_model(10000)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# %history -g -f jupyter_history3.py"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["make_data(10000, oversample=False)\n","\"Done\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dc = DeepCluster('test-0', entity_count=10, train_size=0, num_clusters=25).train_and_evaluate_model(10000)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_and_evaluate_model('test-none-3k', train_size=3000, eval_size=10000, n_clusters=25, entity_count=10)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = evaluate_model('test-none-3k', eval_size=10000, n_clusters=25)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","serialise_model(model, 'test-none-3k')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["models.load_model('./results/test-none-3k')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_model('test-none-10k', train_size=10000, n_clusters=25, entity_count=10)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["evaluate_model('test-none-10k', eval_size=10000, n_clusters=25)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["evaluate_model('test-none-30', train_size=30, eval_size=1000, n_clusters=25)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_and_evaluate_model('test3', train_size=1000, eval_size=10000, n_clusters=25, entity_count=10)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_and_evaluate_model('test1', train_size=10000, eval_size=10000, n_clusters=25, entity_count=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_and_evaluate_model('test1-2', train_size=10000, eval_size=10000, n_clusters=25, entity_count=0)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["evaluate_model('test1-2', eval_size=10000, n_clusters=25, include_unclass=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_model('test1', cluster=\"GMM\", data_rows=1000, entity_count=0, n_clusters=20 )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_model('test1', cluster=\"GMM\", data_rows=1000, entity_count=0, n_clusters=20 )\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["evaluate_model('test1', data_rows=1000, n_clusters=20 )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["evaluate_model('test1', data_rows=1000, entity_count=0, n_clusters=20 )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_and_evaluate_model('test2', train_size=10000, eval_size=10000, n_clusters=15, entity_count=10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_model('reset-metrics', cluster='Kmeans', data_rows=1000, entity_count=0, n_clusters=20 )\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_model('reset-metrics', cluster='Kmeans', data_rows=10000, entity_count=10, n_clusters=15 )\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_model('reset-metrics-dbscan', cluster=\"DBSCAN\", data_rows=1000, entity_count=0, n_clusters=20 )\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_model('reset-metrics-dbscan', cluster=\"DBSCAN\", data_rows=1000, entity_count=10, n_clusters=15)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_model('reset-metrics-dbscan', cluster=\"OPTICS\", data_rows=1000, entity_count=0, n_clusters=20 )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train_model('reset-metrics-optics', cluster=\"OPTICS\", data_rows=1000, entity_count=10, n_clusters=15 )\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["evaluate_model('reset-metrics-dbscan',\n","        entity_count=10,\n","        data_rows=1000,\n","        n_clusters=20,\n","        cluster=\"DBSCAN\",\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# benchmark"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# optimal eps https://iopscience.iop.org/article/10.1088/1755-1315/31/1/012012/pdf\n","\n","from sklearn.neighbors import NearestNeighbors\n","\n","def optimal_eps(X, n_neighbors=10):\n","    neigh = NearestNeighbors(n_neighbors=2)\n","    nbrs = neigh.fit(X)\n","    distances, indices = nbrs.kneighbors(X)\n","    distances = np.sort(distances, axis=0)\n","    distances = distances[:,1]\n","    plt.plot(distances)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def cluster_score(y, y_pred, n_clusters):\n","    \"\"\"\n","    Compute the cluster score.\n","    Arguments:\n","        y: true labels.\n","        y_pred: predicted labels.\n","        n_clusters: number of clusters.\n","    Returns:\n","        cluster score.\n","    \"\"\"\n","    # compute the cluster score\n","    score = 0\n","    for i in range(n_clusters):\n","        score += np.sum(y_pred[y==i]==i)\n","    return score/len(y)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def hypertune_density_clustering():\n","    \"\"\"\n","    hypertune the density clustering algorithms.\n","    \"\"\"\n","    eps_vals = [30000.0, 40000.0, 50000.0]\n","    x, y, mapping, strings = load_data(\n","                                    1000,\n","                                    oversample=True,\n","                                    get_text=True)\n","    print(f\"Optimal epsilon: {optimal_eps(x)}\")\n","    for eps in eps_vals:\n","        # predict cluster labels\n","        print(f\"Predicting...for epsilon={eps}\")\n","        y_pred, _ = do_clustering('DBSCAN', 25, x, params={'eps':eps})\n","        print(f\"ACC: {cluster_score(y, y_pred, 25)}\")\n","        # confusion matrix\n","        cm_width = max(8, len(np.unique(y_pred)) * 2)\n","        cm_width = min(16, cm_width)\n","        plot_confusion(y, y_pred, mapping, size=cm_width, save_dir=None, details=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["hypertune_density_clustering()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def run_benchmark(cluster:str, eval_size:int, n_clusters:int):\n","    x, y, mapping, strings = load_data(\n","                                    eval_size,\n","                                    oversample=False,\n","                                    get_text=True)\n","    save_dir = f'./results/bm/{cluster}'\n","    if not os.path.exists(save_dir):\n","        # create save dir\n","        os.makedirs(save_dir)\n","\n","    \n","    # predict cluster labels\n","    print(\"Predicting...\")\n","    y_pred, _ = do_clustering(cluster, n_clusters, x)\n","    # print(f\"ACC: {cluster_acc(y, y_pred)}\")\n","    \n","    # confusion matrix\n","    cm_width = max(8, len(np.unique(y_pred)) * 2)\n","    cm_width = min(16, cm_width)\n","    plot_confusion(y, y_pred, mapping, save_dir, cm_width)\n","\n","    # show wordclouds for each cluster\n","    print (\"BENCHMARK CLUSTERS\")\n","    clusters = {}\n","    predicted = DataFrame({'text':strings, 'y_pred':y_pred, 'y_true':y})\n","    for cluster_no in range(n_clusters):\n","        y_pred_for_key = predicted[predicted['y_pred']==cluster_no]\n","        true_label = 'UNKNOWN'\n","        modal_value = y_pred_for_key['y_true'].mode()\n","        if len(modal_value)>0:\n","            if modal_value[0] in mapping:\n","                true_label = mapping[modal_value[0]]\n","            # confidence - fraction of this cluster that is actually this cluster\n","            y_true_this_cluster = len(\n","                y_pred_for_key[y_pred_for_key['y_true']==modal_value[0]])\n","            frac = y_true_this_cluster/len(y_pred_for_key)\n","        else:\n","            frac = 0\n","\n","        # wordcloud\n","        unique, counts = np.unique(y_pred_for_key['text'], return_counts=True)\n","        freq_list = np.asarray((unique, counts)).T\n","        freq_list =  sorted(freq_list, key=lambda x: -x[1])[0:50]\n","        freqs = {w: f for w,f in freq_list}\n","        entry = {'freqs':freqs, 'frac':frac, 'n':len(y_pred_for_key)}\n","        if true_label == 'UNKNOWN':\n","            clusters[f\"UNK-{cluster_no}\"] = entry\n","        elif true_label in clusters:\n","            if clusters[true_label]['frac'] < frac:\n","                # we found a better cluster for this label\n","                clusters[true_label] = entry\n","            else:\n","                # this cluster is worse than this one, so it's unknown\n","                clusters[f\"UNK-{cluster_no} Was {true_label}\"] = entry\n","        else:\n","            clusters[true_label] = entry\n","\n","    cluster_list = [{\n","        **clusters[c],\n","        'name': c,\n","        'idx': idx} for idx, c in enumerate(clusters)]\n","    cluster_list = sorted(cluster_list, key=lambda x: -x['frac'])\n","\n","    display_list = []\n","    # show unknown clusters first\n","    for i, cluster in enumerate(cluster_list):\n","        if cluster['name'][0:3] == \"UNK\":\n","            save_file = os.path.join(save_dir,\n","                                     f\"wordcloud-{cluster['name']}.png\")\n","            show_wordcloud(i, cluster, save_file, save_only=True)\n","            display_list.append(cluster)\n","\n","    # next show known clusters\n","    for i, cluster in enumerate(cluster_list):\n","        if cluster['name'][0:3] != \"UNK\":\n","            save_file = os.path.join(save_dir,\n","                                     f\"wordcloud-{cluster['name']}.png\")\n","            show_wordcloud(i, cluster, save_file, save_only=True)\n","            display_list.append(cluster)\n","\n","    \n","    print(write_results_page(display_list, save_dir, cluster))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["run_benchmark('Kmeans', 10000, 25)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["run_benchmark('GMM', 10000, 25)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["run_benchmark('agg', 10000, 25)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.9.12 ('tf-27')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"18e4ecf883516c2f5e8920d96ffc8522d588da1ae71a3f5d592afbc91cfc38c7"}}},"nbformat":4,"nbformat_minor":2}
